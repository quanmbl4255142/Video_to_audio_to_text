# ğŸ¯ Video to Audio Text - Fine-tuning PhoWhisper

Dá»± Ã¡n chuyá»ƒn Ä‘á»•i video thÃ nh audio vÃ  text, vá»›i kháº£ nÄƒng fine-tuning model Whisper/PhoWhisper cho tiáº¿ng Viá»‡t.

## ğŸ“‹ Má»¥c Lá»¥c

- [Tá»•ng Quan Dá»± Ãn](#tá»•ng-quan-dá»±-Ã¡n)
- [SÆ¡ Äá»“ Luá»“ng Tá»•ng Quan](#sÆ¡-Ä‘á»“-luá»“ng-tá»•ng-quan)
- [SÆ¡ Äá»“ Luá»“ng Fine-tuning](#sÆ¡-Ä‘á»“-luá»“ng-fine-tuning)
- [CÃ i Äáº·t](#cÃ i-Ä‘áº·t)
- [HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng](#hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
- [Fine-tuning PhoWhisper-base](#fine-tuning-phowhisper-base)
- [Káº¿t Quáº£ Äáº§u Ra](#káº¿t-quáº£-Ä‘áº§u-ra)
- [TÃ i Liá»‡u Tham Kháº£o](#tÃ i-liá»‡u-tham-kháº£o)

---

## ğŸ¯ Tá»•ng Quan Dá»± Ãn

Dá»± Ã¡n bao gá»“m 2 luá»“ng chÃ­nh:

1. **Luá»“ng Chuyá»ƒn Äá»•i Video â†’ Audio â†’ Text** (app.py)
   - Táº£i video tá»« URL
   - TrÃ­ch xuáº¥t audio tá»« video
   - Chuyá»ƒn Ä‘á»•i audio thÃ nh text báº±ng Whisper/PhoWhisper

2. **Luá»“ng Fine-tuning Model** (fine_tune_whisper.py)
   - Chuáº©n bá»‹ dá»¯ liá»‡u training
   - Fine-tune model Whisper/PhoWhisper
   - Sá»­ dá»¥ng model Ä‘Ã£ fine-tune

---

## ğŸ“Š SÆ¡ Äá»“ Luá»“ng Tá»•ng Quan

```mermaid
graph TB
    Start([Báº¯t Äáº§u]) --> CheckType{Loáº¡i cÃ´ng viá»‡c?}
    
    CheckType -->|Chuyá»ƒn Ä‘á»•i Video| VideoFlow
    CheckType -->|Fine-tuning Model| TrainFlow
    
    subgraph VideoFlow[Luá»“ng Chuyá»ƒn Äá»•i Video]
        V1[Input: Video URL] --> V2[Táº£i Video]
        V2 --> V3[TrÃ­ch xuáº¥t Audio]
        V3 --> V4[Transcribe vá»›i PhoWhisper]
        V4 --> V5[Output: Text]
    end
    
    subgraph TrainFlow[Luá»“ng Fine-tuning]
        T1[Chuáº©n bá»‹ dá»¯ liá»‡u] --> T2[Validate dá»¯ liá»‡u]
        T2 --> T3[Fine-tune Model]
        T3 --> T4[LÆ°u Model]
        T4 --> T5[Sá»­ dá»¥ng Model]
    end
    
    VideoFlow --> End([Káº¿t thÃºc])
    TrainFlow --> End
```

---

## ğŸ”„ SÆ¡ Äá»“ Luá»“ng Fine-tuning Chi Tiáº¿t

```mermaid
flowchart TD
    Start([Báº¯t Äáº§u Fine-tuning]) --> Step1[1. CÃ i Äáº·t Dependencies]
    
    Step1 --> Step2[2. Chuáº©n Bá»‹ Dá»¯ Liá»‡u]
    Step2 --> Step2a[2.1. Äá»c prompts.txt]
    Step2a --> Step2b[2.2. TÃ¬m audio files]
    Step2b --> Step2c[2.3. Táº¡o train.jsonl]
    Step2c --> Step2d[2.4. Táº¡o test.jsonl]
    
    Step2d --> Step3[3. Validate Dá»¯ Liá»‡u]
    Step3 --> Step3a{3.1. Kiá»ƒm tra<br/>Format JSON?}
    Step3a -->|Lá»—i| Step3b[3.2. BÃ¡o lá»—i]
    Step3b --> Step2
    Step3a -->|OK| Step3c{3.3. Kiá»ƒm tra<br/>Audio files?}
    Step3c -->|Lá»—i| Step3b
    Step3c -->|OK| Step3d[3.4. Hiá»ƒn thá»‹ thá»‘ng kÃª]
    
    Step3d --> Step4[4. Fine-tuning]
    Step4 --> Step4a[4.1. Load Model PhoWhisper-base]
    Step4a --> Step4b[4.2. Load Dataset tá»« JSONL]
    Step4b --> Step4c[4.3. Preprocess Audio]
    Step4c --> Step4d[4.4. Training Loop]
    Step4d --> Step4e{4.5. Epochs<br/>hoÃ n thÃ nh?}
    Step4e -->|ChÆ°a| Step4d
    Step4e -->|Xong| Step4f[4.6. LÆ°u Model]
    
    Step4f --> Step5[5. Sá»­ Dá»¥ng Model]
    Step5 --> Step5a[5.1. Load Model Ä‘Ã£ fine-tune]
    Step5a --> Step5b[5.2. Transcribe Audio]
    Step5b --> End([Káº¿t thÃºc])
    
    style Start fill:#90EE90
    style End fill:#FFB6C1
    style Step4 fill:#87CEEB
    style Step4d fill:#FFD700
```

---

## ğŸš€ CÃ i Äáº·t

### 1. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 2. CÃ i Ä‘áº·t GPU support (náº¿u cÃ³ NVIDIA GPU)

```bash
# Kiá»ƒm tra CUDA version
nvidia-smi

# CÃ i PyTorch vá»›i CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ“– HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### Luá»“ng 1: Chuyá»ƒn Äá»•i Video â†’ Audio â†’ Text

#### BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng Flask App

```bash
python app.py
```

**Káº¿t quáº£:**
- Server cháº¡y táº¡i: `http://localhost:5000`
- File log: Console output

#### BÆ°á»›c 2: Sá»­ dá»¥ng Web Interface

1. Má»Ÿ trÃ¬nh duyá»‡t: `http://localhost:5000`
2. Nháº­p URL video
3. Click "Chuyá»ƒn Ä‘á»•i"
4. Nháº­n káº¿t quáº£ text

**Káº¿t quáº£ Ä‘áº§u ra:**
- Text transcription (hiá»ƒn thá»‹ trÃªn web)
- File audio táº¡m (tá»± Ä‘á»™ng xÃ³a sau khi xá»­ lÃ½)

---

### Luá»“ng 2: Fine-tuning PhoWhisper-base

## ğŸ“ Fine-tuning PhoWhisper-base

### Tá»•ng Quan Quy TrÃ¬nh

```mermaid
sequenceDiagram
    participant User
    participant PrepareScript
    participant ValidateScript
    participant TrainScript
    participant Model
    
    User->>PrepareScript: Cháº¡y prepare_jsonl.py
    PrepareScript->>PrepareScript: Äá»c prompts.txt
    PrepareScript->>PrepareScript: TÃ¬m audio files
    PrepareScript->>User: Táº¡o train.jsonl, test.jsonl
    
    User->>ValidateScript: Cháº¡y validate_dataset.py
    ValidateScript->>ValidateScript: Kiá»ƒm tra format
    ValidateScript->>ValidateScript: Kiá»ƒm tra audio files
    ValidateScript->>User: BÃ¡o cÃ¡o validation
    
    User->>TrainScript: Cháº¡y fine_tune_whisper.py
    TrainScript->>Model: Load PhoWhisper-base
    TrainScript->>TrainScript: Load dataset
    TrainScript->>TrainScript: Training loop
    TrainScript->>Model: LÆ°u model Ä‘Ã£ fine-tune
    TrainScript->>User: Model sáºµn sÃ ng
```

---

### BÆ°á»›c 1: Chuáº©n Bá»‹ Dá»¯ Liá»‡u

#### 1.1. Táº¡o train.jsonl

**Lá»‡nh:**
```bash
python prepare_jsonl.py \
    --audio-dir "archive/vivos/train/waves" \
    --prompts-file "archive/vivos/train/prompts.txt" \
    --output "data/train.jsonl" \
    --dataset-name "dataset"
```

**Káº¿t quáº£ Ä‘áº§u ra:**
- **File:** `data/train.jsonl`
- **Format:** JSONL vá»›i 11,660 entries
- **Ná»™i dung máº«u:**
  ```json
  {"audio": "dataset/VIVOSSPK01/VIVOSSPK01_R001.wav", "sentence": "KHÃCH Sáº N"}
  {"audio": "dataset/VIVOSSPK01/VIVOSSPK01_R002.wav", "sentence": "CHá»ˆ Báº°NG CÃCH LUÃ”N Ná»– Lá»°C THÃŒ CUá»I CÃ™NG Báº N Má»šI ÄÆ¯á»¢C Äá»€N ÄÃP"}
  ```

**Thá»‘ng kÃª:**
- âœ… ÄÃ£ Ä‘á»c: 11,660 prompts
- âœ… TÃ¬m tháº¥y: 11,660 audio files
- âœ… Khá»›p: 11,660 cáº·p audio-text

#### 1.2. Táº¡o test.jsonl

**Lá»‡nh:**
```bash
python prepare_jsonl.py \
    --audio-dir "archive/vivos/test/waves" \
    --prompts-file "archive/vivos/test/prompts.txt" \
    --output "data/test.jsonl" \
    --dataset-name "dataset"
```

**Káº¿t quáº£ Ä‘áº§u ra:**
- **File:** `data/test.jsonl`
- **Format:** JSONL vá»›i 760 entries
- **Má»¥c Ä‘Ã­ch:** DÃ¹ng cho validation/evaluation

**Thá»‘ng kÃª:**
- âœ… ÄÃ£ Ä‘á»c: 760 prompts
- âœ… TÃ¬m tháº¥y: 760 audio files
- âœ… Khá»›p: 760 cáº·p audio-text

---

### BÆ°á»›c 2: Validate Dá»¯ Liá»‡u

**Lá»‡nh:**
```bash
python validate_dataset.py \
    --jsonl-file "data/train.jsonl" \
    --audio-dir "archive/vivos/train/waves"
```

**Káº¿t quáº£ Ä‘áº§u ra:**
- **Console output:** BÃ¡o cÃ¡o validation chi tiáº¿t
- **Thá»‘ng kÃª:**
  ```
  ============================================================
  VALIDATION RESULTS
  ============================================================
  
  Tá»•ng sá»‘ entries: 11660
  Entries há»£p lá»‡: 11660
  Entries khÃ´ng há»£p lá»‡: 0
  
  Chi tiáº¿t lá»—i:
    - Missing audio files: 0
    - Empty text: 0
    - Invalid JSON: 0
    - Audio errors: 0
  
  Thá»‘ng kÃª text:
    - Äá»™ dÃ i trung bÃ¬nh: 45.2 kÃ½ tá»±
    - Äá»™ dÃ i min: 5 kÃ½ tá»±
    - Äá»™ dÃ i max: 120 kÃ½ tá»±
  
  Thá»‘ng kÃª audio:
    - Äá»™ dÃ i trung bÃ¬nh: 8.5 giÃ¢y
    - Äá»™ dÃ i min: 1.2 giÃ¢y
    - Äá»™ dÃ i max: 30.5 giÃ¢y
    - Tá»•ng thá»i lÆ°á»£ng: 165.2 giá»
  
  âœ… Dataset há»£p lá»‡! Sáºµn sÃ ng cho fine-tuning.
  ```

---

### BÆ°á»›c 3: Fine-tuning Model

#### 3.1. Vá»›i GPU (Khuyáº¿n nghá»‹)

**Lá»‡nh:**
```bash
python fine_tune_whisper.py \
    --model-name "vinai/PhoWhisper-base" \
    --train-jsonl "data/train.jsonl" \
    --audio-dir "archive/vivos/train/waves" \
    --eval-jsonl "data/test.jsonl" \
    --output-dir "./whisper-finetuned" \
    --num-epochs 3 \
    --batch-size 16 \
    --learning-rate 1e-5 \
    --warmup-steps 500 \
    --fp16
```

**Káº¿t quáº£ Ä‘áº§u ra:**
- **ThÆ° má»¥c:** `./whisper-finetuned/`
- **Files:**
  - `config.json` - Cáº¥u hÃ¬nh model
  - `pytorch_model.bin` hoáº·c `model.safetensors` - Weights cá»§a model
  - `tokenizer.json` - Tokenizer
  - `preprocessor_config.json` - Feature extractor config
  - `training_args.bin` - Training arguments
  - `trainer_state.json` - Training state
  - `checkpoint-*/` - Checkpoints (náº¿u cÃ³)

**Log máº«u:**
```
Äang load model: vinai/PhoWhisper-base
Sá»­ dá»¥ng device: cuda
Äang load dataset tá»«: data/train.jsonl
Sá»‘ entries há»£p lá»‡: 11660
Äang chuáº©n bá»‹ dataset...
Báº¯t Ä‘áº§u training...
Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 729/729 [15:23<00:00, 1.27s/it, loss=0.234]
Epoch 2/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 729/729 [15:18<00:00, 1.26s/it, loss=0.189]
Epoch 3/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 729/729 [15:21<00:00, 1.27s/it, loss=0.156]
Äang lÆ°u model vÃ o: ./whisper-finetuned
HoÃ n thÃ nh fine-tuning!
```

**Thá»i gian Æ°á»›c tÃ­nh:**
- GPU (RTX 3080): ~45-60 phÃºt cho 3 epochs
- GPU (RTX 4090): ~30-40 phÃºt cho 3 epochs

#### 3.2. Vá»›i CPU (Cháº­m hÆ¡n)

**Lá»‡nh:**
```bash
python fine_tune_whisper.py \
    --model-name "vinai/PhoWhisper-base" \
    --train-jsonl "data/train.jsonl" \
    --audio-dir "archive/vivos/train/waves" \
    --output-dir "./whisper-finetuned" \
    --num-epochs 2 \
    --batch-size 4 \
    --learning-rate 1e-5
```

**Káº¿t quáº£ Ä‘áº§u ra:**
- TÆ°Æ¡ng tá»± nhÆ° GPU nhÆ°ng cháº­m hÆ¡n 10-20 láº§n
- **Thá»i gian Æ°á»›c tÃ­nh:** ~10-15 giá» cho 2 epochs

---

### BÆ°á»›c 4: Sá»­ Dá»¥ng Model ÄÃ£ Fine-tune

#### 4.1. Trong Python Script

**Code:**
```python
from transformers import pipeline
import torch

# Load model Ä‘Ã£ fine-tune
pipe = pipeline(
    "automatic-speech-recognition",
    model="./whisper-finetuned",
    device=0 if torch.cuda.is_available() else -1,
)

# Transcribe audio
result = pipe("path/to/audio.wav")
print(result["text"])
```

**Káº¿t quáº£ Ä‘áº§u ra:**
- Text transcription tá»« audio file

#### 4.2. Trong app.py

**Sá»­a code:**
```python
# Thay Ä‘á»•i model path trong app.py
_phowhisper_pipe = pipeline(
    "automatic-speech-recognition",
    model="./whisper-finetuned",  # Model Ä‘Ã£ fine-tune
    device=0 if torch.cuda.is_available() else -1,
)
```

**Káº¿t quáº£:**
- Web app sá»­ dá»¥ng model Ä‘Ã£ fine-tune
- Äá»™ chÃ­nh xÃ¡c cao hÆ¡n vá»›i dá»¯ liá»‡u tÆ°Æ¡ng tá»±

---

## ğŸ“ Káº¿t Quáº£ Äáº§u Ra

### Tá»•ng Há»£p Files Äáº§u Ra

| BÆ°á»›c | Lá»‡nh | File Äáº§u Ra | MÃ´ Táº£ |
|------|------|-------------|-------|
| **1.1** | `prepare_jsonl.py --output train.jsonl` | `data/train.jsonl` | 11,660 entries training data |
| **1.2** | `prepare_jsonl.py --output test.jsonl` | `data/test.jsonl` | 760 entries test data |
| **2** | `validate_dataset.py` | Console output | BÃ¡o cÃ¡o validation |
| **3** | `fine_tune_whisper.py --output-dir ./whisper-finetuned` | `./whisper-finetuned/` | Model Ä‘Ã£ fine-tune |
| **4** | Sá»­ dá»¥ng model | Text transcription | Káº¿t quáº£ transcribe |

### Cáº¥u TrÃºc ThÆ° Má»¥c Sau Fine-tuning

```
./
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.jsonl          # Training data (11,660 entries)
â”‚   â””â”€â”€ test.jsonl            # Test data (760 entries)
â”‚
â”œâ”€â”€ whisper-finetuned/         # Model Ä‘Ã£ fine-tune
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ preprocessor_config.json
â”‚   â”œâ”€â”€ training_args.bin
â”‚   â”œâ”€â”€ trainer_state.json
â”‚   â””â”€â”€ checkpoint-*/          # Checkpoints (náº¿u cÃ³)
â”‚
â””â”€â”€ archive/
    â””â”€â”€ vivos/
        â”œâ”€â”€ train/
        â”‚   â”œâ”€â”€ prompts.txt
        â”‚   â””â”€â”€ waves/         # 11,660 audio files
        â””â”€â”€ test/
            â”œâ”€â”€ prompts.txt
            â””â”€â”€ waves/         # 760 audio files
```

---

## ğŸ“Š Tham Sá»‘ Fine-tuning

### Tham Sá»‘ Máº·c Äá»‹nh (Khuyáº¿n nghá»‹)

| Tham sá»‘ | GiÃ¡ trá»‹ | MÃ´ táº£ |
|---------|---------|-------|
| `--model-name` | `vinai/PhoWhisper-base` | Model base |
| `--num-epochs` | `3` | Sá»‘ epochs |
| `--batch-size` | `16` | Batch size (GPU) / `4` (CPU) |
| `--learning-rate` | `1e-5` | Learning rate |
| `--warmup-steps` | `500` | Warmup steps |
| `--fp16` | `True` | Mixed precision (GPU) |

### Äiá»u Chá»‰nh Tham Sá»‘

**Náº¿u Out of Memory:**
```bash
--batch-size 8          # Giáº£m batch size
--gradient-accumulation-steps 2  # TÄƒng gradient accumulation
```

**Náº¿u Training quÃ¡ cháº­m:**
```bash
--batch-size 32         # TÄƒng batch size (náº¿u Ä‘á»§ VRAM)
--fp16                  # Báº­t mixed precision
```

**Náº¿u Model khÃ´ng cáº£i thiá»‡n:**
```bash
--num-epochs 5          # TÄƒng sá»‘ epochs
--learning-rate 5e-6    # Giáº£m learning rate
```

---

## ğŸ” Troubleshooting

### Lá»—i: Out of Memory

**Giáº£i phÃ¡p:**
```bash
# Giáº£m batch size
--batch-size 4

# TÄƒng gradient accumulation
--gradient-accumulation-steps 4

# Sá»­ dá»¥ng model nhá» hÆ¡n
--model-name "vinai/PhoWhisper-base"  # Thay vÃ¬ large
```

### Lá»—i: File audio khÃ´ng tÃ¬m tháº¥y

**Giáº£i phÃ¡p:**
- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong JSONL
- Äáº£m báº£o `--audio-dir` Ä‘Ãºng
- Cháº¡y `validate_dataset.py` Ä‘á»ƒ kiá»ƒm tra

### Lá»—i: Training quÃ¡ cháº­m

**Giáº£i phÃ¡p:**
- Sá»­ dá»¥ng GPU náº¿u cÃ³
- Báº­t `--fp16`
- TÄƒng `--batch-size` náº¿u Ä‘á»§ VRAM
- Giáº£m sá»‘ epochs hoáº·c dataset size Ä‘á»ƒ test

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- [FINE_TUNING_GUIDE.md](FINE_TUNING_GUIDE.md) - HÆ°á»›ng dáº«n chi tiáº¿t
- [QUICK_START_FINETUNE.md](QUICK_START_FINETUNE.md) - Quick start
- [PhoWhisper trÃªn Hugging Face](https://huggingface.co/vinai/PhoWhisper-base)
- [Transformers Documentation](https://huggingface.co/docs/transformers)

---

## ğŸ¯ TÃ³m Táº¯t Workflow

```mermaid
graph LR
    A[1. prepare_jsonl.py] -->|train.jsonl| B[2. validate_dataset.py]
    B -->|OK| C[3. fine_tune_whisper.py]
    C -->|whisper-finetuned/| D[4. Sá»­ dá»¥ng Model]
    
    style A fill:#90EE90
    style B fill:#87CEEB
    style C fill:#FFD700
    style D fill:#FFB6C1
```

**Thá»i gian Æ°á»›c tÃ­nh:**
- Chuáº©n bá»‹ dá»¯ liá»‡u: ~5 phÃºt
- Validate: ~2 phÃºt
- Fine-tuning (GPU): ~45-60 phÃºt
- Fine-tuning (CPU): ~10-15 giá»

---

## âœ… Checklist Fine-tuning

- [ ] CÃ i Ä‘áº·t dependencies (`pip install -r requirements.txt`)
- [ ] Táº¡o `data/train.jsonl` (11,660 entries)
- [ ] Táº¡o `data/test.jsonl` (760 entries)
- [ ] Validate dá»¯ liá»‡u (khÃ´ng cÃ³ lá»—i)
- [ ] Fine-tuning vá»›i GPU/CPU
- [ ] Kiá»ƒm tra model Ä‘Ã£ lÆ°u táº¡i `./whisper-finetuned/`
- [ ] Test model vá»›i audio máº«u

---

**ChÃºc báº¡n fine-tuning thÃ nh cÃ´ng! ğŸ‰**

