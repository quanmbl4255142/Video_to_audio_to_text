"""
Script ƒë·ªÉ chia dataset th√†nh 3 t·∫≠p: train (80%), test (10%), dev (10%)

Input: archive/vivos/train/ (prompts.txt + waves/)
Output: train.jsonl, test.jsonl, dev.jsonl
"""

import os
import json
import argparse
import random
from pathlib import Path


def load_prompts(prompts_file):
    """
    ƒê·ªçc file transcript v√† tr·∫£ v·ªÅ dictionary {filename: text}
    H·ªó tr·ª£ 2 format:
    1. Format m·ªõi (pipe-separated): FILENAME|TEXT|TIMESTAMPS
    2. Format c≈© (space-separated): FILENAME TEXT
    """
    prompts = {}
    if not os.path.exists(prompts_file):
        print(f"Error: File {prompts_file} kh√¥ng t·ªìn t·∫°i")
        return prompts
    
    with open(prompts_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            
            # Th·ª≠ format m·ªõi tr∆∞·ªõc (pipe-separated): FILENAME|TEXT|TIMESTAMPS
            if '|' in line:
                parts = line.split('|')
                if len(parts) >= 2:
                    filename = parts[0].strip()
                    text = parts[1].strip()
                    # B·ªè qua timestamps (parts[2]) n·∫øu c√≥
                    # L∆∞u filename kh√¥ng c√≥ extension ƒë·ªÉ match v·ªõi audio files
                    filename_without_ext = os.path.splitext(filename)[0]
                    prompts[filename_without_ext] = text
                else:
                    print(f"Warning: D√≤ng {line_num} kh√¥ng ƒë√∫ng format (pipe): {line}")
            else:
                # Format c≈© (space-separated): FILENAME TEXT
                parts = line.split(' ', 1)
                if len(parts) == 2:
                    filename = parts[0]
                    text = parts[1]
                    # L∆∞u filename kh√¥ng c√≥ extension ƒë·ªÉ match v·ªõi audio files
                    filename_without_ext = os.path.splitext(filename)[0]
                    prompts[filename_without_ext] = text
                else:
                    print(f"Warning: D√≤ng {line_num} kh√¥ng ƒë√∫ng format: {line}")
    
    return prompts


def find_audio_files(audio_dir):
    """T√¨m t·∫•t c·∫£ file audio trong th∆∞ m·ª•c (recursive)"""
    audio_files = {}
    audio_extensions = {'.wav', '.mp3', '.flac', '.m4a', '.ogg'}
    
    for root, dirs, files in os.walk(audio_dir):
        for file in files:
            if any(file.lower().endswith(ext) for ext in audio_extensions):
                filepath = os.path.join(root, file)
                # L·∫•y t√™n file kh√¥ng c√≥ extension l√†m key
                filename_without_ext = os.path.splitext(file)[0]
                audio_files[filename_without_ext] = filepath
    
    return audio_files


def create_dataset_entries(audio_dir, prompts_file, negative_ratio=0.3, seed=42):
    """
    T·∫°o danh s√°ch c√°c entries (audio, sentence) t·ª´ prompts v√† audio files
    Bao g·ªìm c·∫£ positive samples (kh·ªõp) v√† negative samples (kh√¥ng kh·ªõp)
    
    Args:
        audio_dir: Th∆∞ m·ª•c ch·ª©a audio files (s·∫Ω d√πng l√†m base path)
        prompts_file: File prompts.txt
        negative_ratio: T·ª∑ l·ªá negative samples so v·ªõi positive (default: 0.3 = 30%)
        seed: Random seed ƒë·ªÉ t·∫°o negative samples reproducible
    
    Returns:
        List of dict: [{"audio": "path", "sentence": "text", "is_match": bool}, ...]
        Path trong JSONL s·∫Ω l√† relative t·ª´ audio_dir
    """
    print(f"ƒêang ƒë·ªçc prompts t·ª´: {prompts_file}")
    prompts = load_prompts(prompts_file)
    print(f"ƒê√£ ƒë·ªçc {len(prompts)} prompts")
    
    print(f"ƒêang t√¨m audio files trong: {audio_dir}")
    audio_files = find_audio_files(audio_dir)
    print(f"ƒê√£ t√¨m th·∫•y {len(audio_files)} audio files")
    
    # T·∫°o positive samples (audio-text kh·ªõp)
    positive_entries = []
    unmatched_audio = []
    unmatched_prompts = []
    
    for filename, text in prompts.items():
        if filename in audio_files:
            audio_path = audio_files[filename]
            # T·∫°o relative path t·ª´ audio_dir
            relative_path = os.path.relpath(audio_path, audio_dir)
            relative_path = relative_path.replace('\\', '/')
            
            positive_entries.append({
                "audio": relative_path,
                "sentence": text,
                "is_match": True
            })
        else:
            unmatched_prompts.append((filename, text))
    
    for filename in audio_files:
        if filename not in prompts:
            unmatched_audio.append(filename)
    
    print(f"\nK·∫øt qu·∫£ matching:")
    print(f"  - S·ªë c·∫∑p audio-text kh·ªõp (positive): {len(positive_entries)}")
    print(f"  - Audio kh√¥ng c√≥ prompt: {len(unmatched_audio)}")
    print(f"  - Prompt kh√¥ng c√≥ audio: {len(unmatched_prompts)}")
    
    # T·∫°o negative samples (audio-text kh√¥ng kh·ªõp)
    print(f"\nƒêang t·∫°o negative samples (t·ª∑ l·ªá {negative_ratio*100:.1f}% so v·ªõi positive)...")
    random.seed(seed)
    
    negative_count = int(len(positive_entries) * negative_ratio)
    negative_entries = []
    
    # T·∫°o negative samples b·∫±ng c√°ch gh√©p audio v·ªõi text kh√¥ng kh·ªõp
    all_audio_keys = list(audio_files.keys())
    all_prompts = list(prompts.items())
    
    created_negative = 0
    max_attempts = negative_count * 10  # Gi·ªõi h·∫°n s·ªë l·∫ßn th·ª≠
    attempts = 0
    
    while created_negative < negative_count and attempts < max_attempts:
        attempts += 1
        
        # Ch·ªçn ng·∫´u nhi√™n m·ªôt audio file
        audio_key = random.choice(all_audio_keys)
        audio_path = audio_files[audio_key]
        relative_path = os.path.relpath(audio_path, audio_dir)
        relative_path = relative_path.replace('\\', '/')
        
        # Ch·ªçn ng·∫´u nhi√™n m·ªôt text kh√¥ng kh·ªõp v·ªõi audio n√†y
        random_prompt_key, random_text = random.choice(all_prompts)
        
        # ƒê·∫£m b·∫£o audio v√† text kh√¥ng kh·ªõp
        if audio_key != random_prompt_key:
            negative_entries.append({
                "audio": relative_path,
                "sentence": random_text,
                "is_match": False
            })
            created_negative += 1
    
    print(f"  - ƒê√£ t·∫°o {len(negative_entries)} negative samples")
    
    # K·∫øt h·ª£p positive v√† negative
    all_entries = positive_entries + negative_entries
    
    # Shuffle ƒë·ªÉ tr·ªôn positive v√† negative
    random.shuffle(all_entries)
    
    print(f"\nT·ªïng s·ªë entries: {len(all_entries)}")
    print(f"  - Positive (kh·ªõp): {len(positive_entries)} ({len(positive_entries)/len(all_entries)*100:.1f}%)")
    print(f"  - Negative (kh√¥ng kh·ªõp): {len(negative_entries)} ({len(negative_entries)/len(all_entries)*100:.1f}%)")
    
    return all_entries


def sample_dataset(entries, ratio=1.0, seed=42):
    """
    L·∫•y m·ªôt ph·∫ßn c·ªßa dataset g·ªëc
    
    Args:
        entries: List of dict entries
        ratio: T·ª∑ l·ªá dataset ƒë·ªÉ l·∫•y (0.0 - 1.0, default: 1.0 = 100%)
        seed: Random seed ƒë·ªÉ reproducible
    
    Returns:
        Sampled entries
    """
    if ratio <= 0.0 or ratio > 1.0:
        raise ValueError(f"Dataset ratio ph·∫£i trong kho·∫£ng (0.0, 1.0], nh∆∞ng ƒë∆∞·ª£c {ratio}")
    
    if ratio >= 1.0:
        return entries
    
    random.seed(seed)
    shuffled = entries.copy()
    random.shuffle(shuffled)
    
    sample_size = int(len(shuffled) * ratio)
    sampled = shuffled[:sample_size]
    
    print(f"\nL·∫•y m·∫´u dataset:")
    print(f"  - Dataset g·ªëc: {len(entries)} entries")
    print(f"  - T·ª∑ l·ªá: {ratio*100:.1f}%")
    print(f"  - Dataset sau khi l·∫•y m·∫´u: {len(sampled)} entries")
    
    return sampled


def split_dataset(entries, train_ratio=0.8, test_ratio=0.1, dev_ratio=0.1, seed=42):
    """
    Chia dataset th√†nh 3 t·∫≠p: train, test, dev
    ƒê·∫£m b·∫£o m·ªói t·∫≠p ƒë·ªÅu c√≥ c·∫£ positive v√† negative samples
    
    Args:
        entries: List of dict entries (c√≥ field "is_match")
        train_ratio: T·ª∑ l·ªá train (default: 0.8)
        test_ratio: T·ª∑ l·ªá test (default: 0.1)
        dev_ratio: T·ª∑ l·ªá dev (default: 0.1)
        seed: Random seed ƒë·ªÉ reproducible
    
    Returns:
        train_entries, test_entries, dev_entries
    """
    # Validate ratios
    total_ratio = train_ratio + test_ratio + dev_ratio
    if abs(total_ratio - 1.0) > 0.001:
        raise ValueError(f"T·ªïng t·ª∑ l·ªá ph·∫£i b·∫±ng 1.0, nh∆∞ng ƒë∆∞·ª£c {total_ratio}")
    
    # T√°ch positive v√† negative entries
    positive_entries = [e for e in entries if e.get("is_match", True)]
    negative_entries = [e for e in entries if not e.get("is_match", True)]
    
    print(f"\nPh√¢n lo·∫°i entries:")
    print(f"  - Positive: {len(positive_entries)}")
    print(f"  - Negative: {len(negative_entries)}")
    
    # Shuffle ri√™ng positive v√† negative v·ªõi seed
    random.seed(seed)
    shuffled_positive = positive_entries.copy()
    shuffled_negative = negative_entries.copy()
    random.shuffle(shuffled_positive)
    random.shuffle(shuffled_negative)
    
    # Chia positive samples
    pos_total = len(shuffled_positive)
    pos_train_size = int(pos_total * train_ratio)
    pos_test_size = int(pos_total * test_ratio)
    
    pos_train = shuffled_positive[:pos_train_size]
    pos_test = shuffled_positive[pos_train_size:pos_train_size + pos_test_size]
    pos_dev = shuffled_positive[pos_train_size + pos_test_size:]
    
    # Chia negative samples
    neg_total = len(shuffled_negative)
    neg_train_size = int(neg_total * train_ratio)
    neg_test_size = int(neg_total * test_ratio)
    
    neg_train = shuffled_negative[:neg_train_size]
    neg_test = shuffled_negative[neg_train_size:neg_train_size + neg_test_size]
    neg_dev = shuffled_negative[neg_train_size + neg_test_size:]
    
    # K·∫øt h·ª£p positive v√† negative cho m·ªói t·∫≠p
    train_entries = pos_train + neg_train
    test_entries = pos_test + neg_test
    dev_entries = pos_dev + neg_dev
    
    # Shuffle l·∫°i m·ªói t·∫≠p ƒë·ªÉ tr·ªôn positive v√† negative
    random.shuffle(train_entries)
    random.shuffle(test_entries)
    random.shuffle(dev_entries)
    
    total = len(entries)
    
    print(f"\nChia dataset (seed={seed}):")
    print(f"  - Train: {len(train_entries)} ({len(train_entries)/total*100:.1f}%)")
    print(f"    + Positive: {len(pos_train)} ({len(pos_train)/len(train_entries)*100:.1f}%)")
    print(f"    + Negative: {len(neg_train)} ({len(neg_train)/len(train_entries)*100:.1f}%)")
    print(f"  - Test: {len(test_entries)} ({len(test_entries)/total*100:.1f}%)")
    print(f"    + Positive: {len(pos_test)} ({len(pos_test)/len(test_entries)*100:.1f}%)")
    print(f"    + Negative: {len(neg_test)} ({len(neg_test)/len(test_entries)*100:.1f}%)")
    print(f"  - Dev: {len(dev_entries)} ({len(dev_entries)/total*100:.1f}%)")
    print(f"    + Positive: {len(pos_dev)} ({len(pos_dev)/len(dev_entries)*100:.1f}%)")
    print(f"    + Negative: {len(neg_dev)} ({len(neg_dev)/len(dev_entries)*100:.1f}%)")
    print(f"  - Total: {total}")
    
    return train_entries, test_entries, dev_entries


def write_jsonl(entries, output_file):
    """Ghi entries ra file JSONL"""
    print(f"ƒêang ghi file JSONL: {output_file}")
    with open(output_file, 'w', encoding='utf-8') as f:
        for item in entries:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    print(f"ƒê√£ ghi {len(entries)} entries v√†o {output_file}")


def main():
    parser = argparse.ArgumentParser(description='Chia dataset th√†nh train/test/dev (80/10/10) v·ªõi c·∫£ positive v√† negative samples')
    parser.add_argument('ratio', type=float, nargs='?', default=None,
                        help='T·ª∑ l·ªá dataset g·ªëc ƒë·ªÉ s·ª≠ d·ª•ng (positional argument, v√≠ d·ª•: 0.1 = 10%%)')
    parser.add_argument('--archive-dir', type=str, default='archive/vivos/train',
                        help='Th∆∞ m·ª•c ch·ª©a dataset (default: archive/vivos/train)')
    parser.add_argument('--transcript-file', type=str, default=None,
                        help='File transcript (default: t·ª± ƒë·ªông t√¨m prompts.txt ho·∫∑c transcriptAll.txt trong archive-dir)')
    parser.add_argument('--audio-dir', type=str, default=None,
                        help='Th∆∞ m·ª•c ch·ª©a audio files (default: t·ª± ƒë·ªông t√¨m mp3/ ho·∫∑c waves/ trong archive-dir)')
    parser.add_argument('--output-dir', type=str, default='data',
                        help='Th∆∞ m·ª•c output ƒë·ªÉ l∆∞u JSONL files (default: data)')
    parser.add_argument('--train-ratio', type=float, default=0.8,
                        help='T·ª∑ l·ªá train (default: 0.8)')
    parser.add_argument('--test-ratio', type=float, default=0.1,
                        help='T·ª∑ l·ªá test (default: 0.1)')
    parser.add_argument('--dev-ratio', type=float, default=0.1,
                        help='T·ª∑ l·ªá dev (default: 0.1)')
    parser.add_argument('--negative-ratio', type=float, default=0.3,
                        help='T·ª∑ l·ªá negative samples so v·ªõi positive (default: 0.3 = 30%%)')
    parser.add_argument('--dataset-ratio', type=float, default=1.0,
                        help='T·ª∑ l·ªá dataset g·ªëc ƒë·ªÉ s·ª≠ d·ª•ng (default: 1.0 = 100%%, v√≠ d·ª•: 0.1 = 10%%) - c√≥ th·ªÉ d√πng positional argument thay th·∫ø')
    parser.add_argument('--seed', type=int, default=42,
                        help='Random seed ƒë·ªÉ reproducible (default: 42)')
    args = parser.parse_args()
    
    # N·∫øu c√≥ positional argument, ∆∞u ti√™n s·ª≠ d·ª•ng n√≥
    if args.ratio is not None:
        dataset_ratio = args.ratio
    else:
        # N·∫øu kh√¥ng c√≥ positional argument, d√πng gi√° tr·ªã t·ª´ --dataset-ratio (m·∫∑c ƒë·ªãnh 1.0)
        dataset_ratio = args.dataset_ratio
    
    # Validate dataset_ratio
    if dataset_ratio <= 0.0 or dataset_ratio > 1.0:
        raise ValueError(f"Dataset ratio ph·∫£i trong kho·∫£ng (0.0, 1.0], nh∆∞ng ƒë∆∞·ª£c {dataset_ratio}")
    
    # T√¨m transcript file v√† waves/ trong archive_dir
    archive_dir = os.path.abspath(args.archive_dir)  # Convert to absolute path
    
    # X√°c ƒë·ªãnh file transcript
    transcript_search_paths = []
    archive_root = os.path.dirname(archive_dir.rstrip(os.sep))
    archive_super_root = os.path.dirname(archive_root.rstrip(os.sep)) if archive_root else None

    if args.transcript_file:
        prompts_file = os.path.abspath(args.transcript_file)
        transcript_search_paths.append(prompts_file)
    else:
        transcript_candidates = [
            'transcriptAll.txt',
            'transcript_all.txt',
            'transcript.txt',
            'prompts.txt',
            'prompt.txt',
            'metadata.txt',
            'metadata.csv',
        ]
        found_transcript = None
        search_dirs = []
        for search_dir in [archive_dir, archive_root, archive_super_root]:
            if search_dir and search_dir not in search_dirs:
                search_dirs.append(search_dir)

        # T√¨m transcript trong c√°c th∆∞ m·ª•c ∆∞u ti√™n (kh√¥ng ƒë·ªá quy)
        for search_dir in search_dirs:
            for candidate in transcript_candidates:
                candidate_path = os.path.join(search_dir, candidate)
                if candidate_path not in transcript_search_paths:
                    transcript_search_paths.append(candidate_path)
                if os.path.exists(candidate_path):
                    found_transcript = candidate_path
                    break
            if found_transcript:
                break

        # N·∫øu ch∆∞a t√¨m th·∫•y, duy·ªát to√†n b·ªô th∆∞ m·ª•c con
        if not found_transcript:
            for search_dir in search_dirs:
                for root, _, files in os.walk(search_dir):
                    for candidate in transcript_candidates:
                        if candidate in files:
                            found_transcript = os.path.join(root, candidate)
                            transcript_search_paths.append(found_transcript)
                            break
                    if found_transcript:
                        break
                if found_transcript:
                    break

        if found_transcript:
            prompts_file = os.path.abspath(found_transcript)
            print(f"‚úì T√¨m th·∫•y file transcript: {prompts_file}")
        else:
            fallback_root = None
            for root_candidate in [archive_super_root, archive_root, archive_dir]:
                if root_candidate:
                    fallback_root = root_candidate
                    break
            prompts_file = os.path.join(fallback_root, 'prompts.txt') if fallback_root else 'prompts.txt'
            if prompts_file not in transcript_search_paths:
                transcript_search_paths.append(prompts_file)
    
    # X√°c ƒë·ªãnh th∆∞ m·ª•c audio
    audio_search_paths = []
    if args.audio_dir:
        audio_dir = os.path.abspath(args.audio_dir)
        audio_search_paths.append(audio_dir)
    else:
        audio_candidates = [
            'mp3',
            'mp3s',
            'wav',
            'wavs',
            'waves',
            'audio',
        ]
        found_audio_dir = None
        audio_search_dirs = []
        for search_dir in [archive_dir, archive_root, archive_super_root]:
            if search_dir and search_dir not in audio_search_dirs:
                audio_search_dirs.append(search_dir)
        # ∆Øu ti√™n t√¨m tr·ª±c ti·∫øp trong c√°c th∆∞ m·ª•c ∆∞u ti√™n
        for search_dir in audio_search_dirs:
            for candidate in audio_candidates:
                candidate_path = os.path.join(search_dir, candidate)
                if candidate_path not in audio_search_paths:
                    audio_search_paths.append(candidate_path)
                if os.path.isdir(candidate_path):
                    found_audio_dir = candidate_path
                    break
            if found_audio_dir:
                break
        # N·∫øu ch∆∞a th·∫•y, duy·ªát ƒë·ªá quy
        if not found_audio_dir:
            for search_dir in audio_search_dirs:
                for root, dirs, _ in os.walk(search_dir):
                    for candidate in audio_candidates:
                        if candidate in dirs:
                            found_audio_dir = os.path.join(root, candidate)
                            audio_search_paths.append(found_audio_dir)
                            break
                    if found_audio_dir:
                        break
                if found_audio_dir:
                    break
        if found_audio_dir:
            audio_dir = os.path.abspath(found_audio_dir)
            print(f"‚úì T√¨m th·∫•y th∆∞ m·ª•c audio: {audio_dir}")
        else:
            fallback_root = None
            for root_candidate in [archive_super_root, archive_root, archive_dir]:
                if root_candidate:
                    fallback_root = root_candidate
                    break
            audio_dir = os.path.join(fallback_root, 'mp3') if fallback_root else 'mp3'
            if audio_dir not in audio_search_paths:
                audio_search_paths.append(audio_dir)
    
    if not os.path.exists(prompts_file):
        print(f"Error: File transcript kh√¥ng t·ªìn t·∫°i: {prompts_file}")
        if transcript_search_paths:
            print("  ƒê√£ th·ª≠ t√¨m trong:")
            for path in transcript_search_paths:
                print(f"    - {path}")
        print("  H√£y ch·ªâ ƒë·ªãnh --transcript-file ho·∫∑c ƒë·∫£m b·∫£o c√≥ file transcript h·ª£p l·ªá trong archive-dir")
        return
    
    if not os.path.exists(audio_dir):
        print(f"Error: Th∆∞ m·ª•c audio kh√¥ng t·ªìn t·∫°i: {audio_dir}")
        if audio_search_paths:
            print("  ƒê√£ th·ª≠ t√¨m trong:")
            for path in audio_search_paths:
                print(f"    - {path}")
        print("  H√£y ch·ªâ ƒë·ªãnh --audio-dir ho·∫∑c ƒë·∫£m b·∫£o c√≥ th∆∞ m·ª•c ch·ª©a audio trong archive-dir")
        return
    
    # T·∫°o output directory
    os.makedirs(args.output_dir, exist_ok=True)
    
    # T·∫°o dataset entries (bao g·ªìm c·∫£ positive v√† negative)
    # audio_dir s·∫Ω ƒë∆∞·ª£c d√πng l√†m base path trong JSONL (relative paths)
    entries = create_dataset_entries(
        audio_dir, 
        prompts_file, 
        negative_ratio=args.negative_ratio,
        seed=args.seed
    )
    
    if len(entries) == 0:
        print("Error: Kh√¥ng c√≥ entries n√†o ƒë·ªÉ chia")
        return
    
    # L·∫•y m·∫´u dataset n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu (v√≠ d·ª•: ch·ªâ l·∫•y 10% dataset g·ªëc)
    if dataset_ratio < 1.0:
        entries = sample_dataset(entries, ratio=dataset_ratio, seed=args.seed)
    
    if len(entries) == 0:
        print("Error: Kh√¥ng c√≥ entries n√†o sau khi l·∫•y m·∫´u")
        return
    
    # Chia dataset (ƒë·∫£m b·∫£o m·ªói t·∫≠p ƒë·ªÅu c√≥ c·∫£ positive v√† negative)
    train_entries, test_entries, dev_entries = split_dataset(
        entries,
        train_ratio=args.train_ratio,
        test_ratio=args.test_ratio,
        dev_ratio=args.dev_ratio,
        seed=args.seed
    )
    
    # Ghi c√°c file JSONL
    train_file = os.path.join(args.output_dir, 'train.jsonl')
    test_file = os.path.join(args.output_dir, 'test.jsonl')
    dev_file = os.path.join(args.output_dir, 'dev.jsonl')
    
    write_jsonl(train_entries, train_file)
    write_jsonl(test_entries, test_file)
    write_jsonl(dev_entries, dev_file)
    
    print(f"\n‚úÖ Ho√†n th√†nh! ƒê√£ t·∫°o 3 file JSONL trong th∆∞ m·ª•c: {args.output_dir}")
    print(f"  - {train_file}")
    print(f"  - {test_file}")
    print(f"  - {dev_file}")
    print(f"\nüìä M·ªói file JSONL ƒë·ªÅu ch·ª©a c·∫£ positive (is_match=true) v√† negative (is_match=false) samples")


if __name__ == '__main__':
    main()

