# üìÅ C√°c File ƒê√£ T·∫°o Cho Fine-tuning

## Scripts Ch√≠nh

### 1. `prepare_jsonl.py`
**M·ª•c ƒë√≠ch**: Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu audio v√† text th√†nh format JSONL chu·∫©n

**S·ª≠ d·ª•ng**:
```bash
python prepare_jsonl.py \
    --audio-dir "archive/vivos/train/waves" \
    --prompts-file "archive/vivos/train/prompts.txt" \
    --output "train.jsonl" \
    --dataset-name "dataset"
```

**Ch·ª©c nƒÉng**:
- ƒê·ªçc file prompts.txt v·ªõi format: `FILENAME TEXT`
- T√¨m c√°c file audio t∆∞∆°ng ·ª©ng
- T·∫°o file JSONL v·ªõi format: `{"audio": "path", "sentence": "text"}`

---

### 2. `validate_dataset.py`
**M·ª•c ƒë√≠ch**: Ki·ªÉm tra v√† validate d·ªØ li·ªáu tr∆∞·ªõc khi fine-tuning

**S·ª≠ d·ª•ng**:
```bash
python validate_dataset.py \
    --jsonl-file "train.jsonl" \
    --audio-dir "archive/vivos/train/waves"
```

**Ch·ª©c nƒÉng**:
- Ki·ªÉm tra format JSON h·ª£p l·ªá
- Ki·ªÉm tra file audio t·ªìn t·∫°i
- Ki·ªÉm tra text kh√¥ng r·ªóng
- Ki·ªÉm tra audio c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c
- Hi·ªÉn th·ªã th·ªëng k√™ (ƒë·ªô d√†i text, th·ªùi l∆∞·ª£ng audio)

---

### 3. `fine_tune_whisper.py`
**M·ª•c ƒë√≠ch**: Script ch√≠nh ƒë·ªÉ fine-tune Whisper/PhoWhisper

**S·ª≠ d·ª•ng**:
```bash
python fine_tune_whisper.py \
    --model-name "vinai/PhoWhisper-base" \
    --train-jsonl "train.jsonl" \
    --audio-dir "archive/vivos/train/waves" \
    --output-dir "./whisper-finetuned" \
    --num-epochs 3 \
    --batch-size 16 \
    --fp16
```

**Ch·ª©c nƒÉng**:
- Load model Whisper/PhoWhisper t·ª´ Hugging Face
- Load v√† x·ª≠ l√Ω dataset t·ª´ JSONL
- Fine-tune model v·ªõi c√°c tham s·ªë t√πy ch·ªânh
- L∆∞u model ƒë√£ fine-tune

**Tham s·ªë ch√≠nh**:
- `--model-name`: Model base (vinai/PhoWhisper-base, openai/whisper-base, ...)
- `--train-jsonl`: File JSONL training data
- `--audio-dir`: Th∆∞ m·ª•c ch·ª©a audio files
- `--output-dir`: Th∆∞ m·ª•c l∆∞u model
- `--num-epochs`: S·ªë epochs (m·∫∑c ƒë·ªãnh: 3)
- `--batch-size`: Batch size (m·∫∑c ƒë·ªãnh: 16)
- `--learning-rate`: Learning rate (m·∫∑c ƒë·ªãnh: 1e-5)
- `--fp16`: Mixed precision training (cho GPU)
- `--eval-jsonl`: File JSONL evaluation (optional)

---

## T√†i Li·ªáu

### 4. `FINE_TUNING_GUIDE.md`
**H∆∞·ªõng d·∫´n chi ti·∫øt ƒë·∫ßy ƒë·ªß** v·ªÅ:
- Y√™u c·∫ßu h·ªá th·ªëng
- C√†i ƒë·∫∑t
- Chu·∫©n b·ªã d·ªØ li·ªáu
- Validate d·ªØ li·ªáu
- Fine-tuning (c∆° b·∫£n v√† n√¢ng cao)
- S·ª≠ d·ª•ng model ƒë√£ fine-tune
- Troubleshooting
- Best practices

### 5. `QUICK_START_FINETUNE.md`
**H∆∞·ªõng d·∫´n nhanh** ƒë·ªÉ b·∫Øt ƒë·∫ßu trong 5 ph√∫t:
- C√°c b∆∞·ªõc c∆° b·∫£n
- L·ªánh m·∫´u
- Format JSONL
- Troubleshooting nhanh

---

## Scripts V√≠ D·ª•

### 6. `example_prepare_vivos.sh`
Script bash v√≠ d·ª• ƒë·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu VIVOS:
- T·∫°o train.jsonl v√† test.jsonl
- Validate datasets

### 7. `example_finetune.sh`
Script bash v√≠ d·ª• ƒë·ªÉ fine-tune:
- Fine-tune v·ªõi PhoWhisper-base
- C√°c tham s·ªë m·∫∑c ƒë·ªãnh

---

## File C·∫•u H√¨nh

### 8. `requirements.txt` (ƒë√£ c·∫≠p nh·∫≠t)
ƒê√£ th√™m c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt:
- `datasets>=2.14.0` - ƒê·ªÉ load v√† x·ª≠ l√Ω dataset
- `accelerate>=0.20.0` - ƒê·ªÉ tƒÉng t·ªëc training
- `librosa>=0.10.0` - X·ª≠ l√Ω audio
- `soundfile>=0.12.0` - ƒê·ªçc file audio

---

## Workflow ƒê·ªÅ Xu·∫•t

1. **Chu·∫©n b·ªã d·ªØ li·ªáu**:
   ```bash
   python prepare_jsonl.py --audio-dir ... --prompts-file ... --output train.jsonl
   ```

2. **Validate**:
   ```bash
   python validate_dataset.py --jsonl-file train.jsonl --audio-dir ...
   ```

3. **Fine-tune**:
   ```bash
   python fine_tune_whisper.py --model-name vinai/PhoWhisper-base --train-jsonl train.jsonl ...
   ```

4. **S·ª≠ d·ª•ng model**:
   ```python
   from transformers import pipeline
   pipe = pipeline("automatic-speech-recognition", model="./whisper-finetuned")
   ```

---

## Format JSONL Chu·∫©n

M·ªói d√≤ng trong file JSONL:

```json
{"audio": "dataset/ad001.wav", "sentence": "S·∫Øm T·∫øt c√πng Shopee nh·∫≠n ngay qu√† h·∫•p d·∫´n!"}
{"audio": "dataset/ad002.wav", "sentence": "D·∫ßu g·ªôi Head & Shoulders ƒë√°nh bay g√†u t·ª©c th√¨."}
{"audio": "dataset/ad003.wav", "sentence": "Kh√°m ph√° h∆∞∆°ng v·ªã m·ªõi c√πng Pepsi v·ªã chanh!"}
```

**L∆∞u √Ω**:
- `audio`: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio (relative ho·∫∑c absolute)
- `sentence`: Text transcription t∆∞∆°ng ·ª©ng
- M·ªói d√≤ng l√† m·ªôt JSON object h·ª£p l·ªá

---

## Models C√≥ S·∫µn

### PhoWhisper (Khuy·∫øn ngh·ªã cho ti·∫øng Vi·ªát):
- `vinai/PhoWhisper-base` - C√¢n b·∫±ng, nhanh
- `vinai/PhoWhisper-large` - Ch√≠nh x√°c nh·∫•t

### Whisper (OpenAI):
- `openai/whisper-tiny` - Nh·ªè nh·∫•t
- `openai/whisper-base` - C√¢n b·∫±ng
- `openai/whisper-small` - Ch√≠nh x√°c h∆°n
- `openai/whisper-medium` - R·∫•t ch√≠nh x√°c
- `openai/whisper-large-v3` - Ch√≠nh x√°c nh·∫•t

---

## L∆∞u √ù

- Lu√¥n validate d·ªØ li·ªáu tr∆∞·ªõc khi fine-tune
- B·∫Øt ƒë·∫ßu v·ªõi model nh·ªè (base) ƒë·ªÉ test
- S·ª≠ d·ª•ng GPU n·∫øu c√≥ th·ªÉ (nhanh h∆°n 10-20 l·∫ßn)
- Fine-tune v·ªõi √≠t d·ªØ li·ªáu tr∆∞·ªõc (100-500 samples) ƒë·ªÉ test workflow
- Xem `FINE_TUNING_GUIDE.md` ƒë·ªÉ bi·∫øt chi ti·∫øt ƒë·∫ßy ƒë·ªß

---

**Ch√∫c b·∫°n fine-tuning th√†nh c√¥ng! üéâ**


