# ğŸ¯ HÆ°á»›ng Dáº«n Fine-tuning Whisper/PhoWhisper

HÆ°á»›ng dáº«n chi tiáº¿t Ä‘á»ƒ fine-tune model Whisper hoáº·c PhoWhisper vá»›i dá»¯ liá»‡u tiáº¿ng Viá»‡t cá»§a báº¡n.

## ğŸ“‹ Má»¥c Lá»¥c

1. [YÃªu Cáº§u Há»‡ Thá»‘ng](#yÃªu-cáº§u-há»‡-thá»‘ng)
2. [CÃ i Äáº·t](#cÃ i-Ä‘áº·t)
3. [Chuáº©n Bá»‹ Dá»¯ Liá»‡u](#chuáº©n-bá»‹-dá»¯-liá»‡u)
4. [Validate Dá»¯ Liá»‡u](#validate-dá»¯-liá»‡u)
5. [Fine-tuning](#fine-tuning)
6. [Sá»­ Dá»¥ng Model ÄÃ£ Fine-tune](#sá»­-dá»¥ng-model-Ä‘Ã£-fine-tune)
7. [Troubleshooting](#troubleshooting)

---

## ğŸ–¥ï¸ YÃªu Cáº§u Há»‡ Thá»‘ng

### Tá»‘i Thiá»ƒu:
- **CPU**: 4 cores
- **RAM**: 8GB
- **Storage**: 10GB trá»‘ng
- **GPU**: KhÃ´ng báº¯t buá»™c nhÆ°ng khuyáº¿n nghá»‹ (NVIDIA GPU vá»›i 6GB+ VRAM)

### Khuyáº¿n Nghá»‹:
- **CPU**: 8+ cores
- **RAM**: 16GB+
- **Storage**: 50GB+ trá»‘ng (cho model vÃ  cache)
- **GPU**: NVIDIA GPU vá»›i CUDA support (8GB+ VRAM)

---

## ğŸ“¦ CÃ i Äáº·t

### 1. CÃ i Ä‘áº·t dependencies:

```bash
pip install -r requirements.txt
```

### 2. CÃ i Ä‘áº·t thÃªm cho GPU (náº¿u cÃ³ NVIDIA GPU):

```bash
# Kiá»ƒm tra CUDA version
nvidia-smi

# CÃ i PyTorch vá»›i CUDA (thay Ä‘á»•i cu118 theo CUDA version cá»§a báº¡n)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ“ Chuáº©n Bá»‹ Dá»¯ Liá»‡u

### Format JSONL Chuáº©n

Dá»¯ liá»‡u training pháº£i á»Ÿ format JSONL vá»›i cáº¥u trÃºc:

```json
{"audio": "dataset/ad001.wav", "sentence": "Sáº¯m Táº¿t cÃ¹ng Shopee nháº­n ngay quÃ  háº¥p dáº«n!"}
{"audio": "dataset/ad002.wav", "sentence": "Dáº§u gá»™i Head & Shoulders Ä‘Ã¡nh bay gÃ u tá»©c thÃ¬."}
{"audio": "dataset/ad003.wav", "sentence": "KhÃ¡m phÃ¡ hÆ°Æ¡ng vá»‹ má»›i cÃ¹ng Pepsi vá»‹ chanh!"}
```

**LÆ°u Ã½:**
- Má»—i dÃ²ng lÃ  má»™t JSON object
- `audio`: ÄÆ°á»ng dáº«n Ä‘áº¿n file audio (relative hoáº·c absolute)
- `sentence`: Text transcription tÆ°Æ¡ng á»©ng

### Táº¡o JSONL tá»« dá»¯ liá»‡u cÃ³ sáºµn

#### VÃ­ dá»¥ 1: Tá»« VIVOS dataset

```bash
python prepare_jsonl.py \
    --audio-dir "archive/vivos/train/waves" \
    --prompts-file "archive/vivos/train/prompts.txt" \
    --output "train.jsonl" \
    --dataset-name "dataset"
```

#### VÃ­ dá»¥ 2: Tá»« thÆ° má»¥c audio vÃ  file text riÃªng

Náº¿u báº¡n cÃ³:
- ThÆ° má»¥c `my_audio/` chá»©a cÃ¡c file `.wav`
- File `transcriptions.txt` vá»›i format: `filename text`

Táº¡o file `prompts.txt`:
```bash
# Format: FILENAME TEXT
ad001 Sáº¯m Táº¿t cÃ¹ng Shopee nháº­n ngay quÃ  háº¥p dáº«n!
ad002 Dáº§u gá»™i Head & Shoulders Ä‘Ã¡nh bay gÃ u tá»©c thÃ¬.
```

Sau Ä‘Ã³ cháº¡y:
```bash
python prepare_jsonl.py \
    --audio-dir "my_audio" \
    --prompts-file "transcriptions.txt" \
    --output "train.jsonl" \
    --dataset-name "dataset"
```

### YÃªu Cáº§u Vá» Dá»¯ Liá»‡u

- **Sá»‘ lÆ°á»£ng tá»‘i thiá»ƒu**: 100 samples (khuyáº¿n nghá»‹ 1000+)
- **Äá»™ dÃ i audio**: 1-30 giÃ¢y (tá»‘i Æ°u: 5-15 giÃ¢y)
- **Format audio**: WAV, MP3, FLAC, M4A, OGG
- **Sample rate**: Tá»± Ä‘á»™ng resample vá» 16kHz
- **Cháº¥t lÆ°á»£ng**: Audio rÃµ rÃ ng, Ã­t noise
- **Text**: ChÃ­nh xÃ¡c, khÃ´ng cÃ³ lá»—i chÃ­nh táº£

---

## âœ… Validate Dá»¯ Liá»‡u

**LuÃ´n validate dá»¯ liá»‡u trÆ°á»›c khi fine-tuning!**

```bash
python validate_dataset.py \
    --jsonl-file "train.jsonl" \
    --audio-dir "archive/vivos/train/waves"
```

Script sáº½ kiá»ƒm tra:
- âœ… Format JSON há»£p lá»‡
- âœ… File audio tá»“n táº¡i
- âœ… Text khÃ´ng rá»—ng
- âœ… Audio cÃ³ thá»ƒ Ä‘á»c Ä‘Æ°á»£c
- âœ… Thá»‘ng kÃª Ä‘á»™ dÃ i audio vÃ  text

**Output máº«u:**
```
============================================================
VALIDATION RESULTS
============================================================

Tá»•ng sá»‘ entries: 1000
Entries há»£p lá»‡: 998
Entries khÃ´ng há»£p lá»‡: 2

Thá»‘ng kÃª text:
  - Äá»™ dÃ i trung bÃ¬nh: 45.2 kÃ½ tá»±
  - Äá»™ dÃ i min: 5 kÃ½ tá»±
  - Äá»™ dÃ i max: 120 kÃ½ tá»±

Thá»‘ng kÃª audio:
  - Äá»™ dÃ i trung bÃ¬nh: 8.5 giÃ¢y
  - Tá»•ng thá»i lÆ°á»£ng: 141.67 phÃºt (2.36 giá»)

âœ… Dataset há»£p lá»‡! Sáºµn sÃ ng cho fine-tuning.
```

---

## ğŸš€ Fine-tuning

### CÃ¡c Model CÃ³ Sáºµn

1. **Whisper (OpenAI)**:
   - `openai/whisper-tiny` - Nhá» nháº¥t, nhanh nháº¥t
   - `openai/whisper-base` - CÃ¢n báº±ng (khuyáº¿n nghá»‹)
   - `openai/whisper-small` - ChÃ­nh xÃ¡c hÆ¡n
   - `openai/whisper-medium` - Ráº¥t chÃ­nh xÃ¡c
   - `openai/whisper-large-v3` - ChÃ­nh xÃ¡c nháº¥t (lá»›n nháº¥t)

2. **PhoWhisper (VinAI - tá»‘i Æ°u cho tiáº¿ng Viá»‡t)**:
   - `vinai/PhoWhisper-base` - Khuyáº¿n nghá»‹ cho tiáº¿ng Viá»‡t
   - `vinai/PhoWhisper-large` - ChÃ­nh xÃ¡c nháº¥t cho tiáº¿ng Viá»‡t

### Fine-tuning CÆ¡ Báº£n

```bash
python fine_tune_whisper.py \
    --model-name "vinai/PhoWhisper-base" \
    --train-jsonl "train.jsonl" \
    --audio-dir "archive/vivos/train/waves" \
    --output-dir "./whisper-finetuned" \
    --num-epochs 3 \
    --batch-size 16 \
    --learning-rate 1e-5
```

### Fine-tuning NÃ¢ng Cao

```bash
python fine_tune_whisper.py \
    --model-name "vinai/PhoWhisper-large" \
    --train-jsonl "train.jsonl" \
    --audio-dir "archive/vivos/train/waves" \
    --eval-jsonl "test.jsonl" \
    --output-dir "./whisper-finetuned-large" \
    --num-epochs 5 \
    --batch-size 8 \
    --learning-rate 5e-6 \
    --warmup-steps 1000 \
    --gradient-accumulation-steps 2 \
    --fp16
```

### Tham Sá»‘ Quan Trá»ng

| Tham sá»‘ | MÃ´ táº£ | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh | Khuyáº¿n nghá»‹ |
|---------|-------|------------------|-------------|
| `--model-name` | Model base Ä‘á»ƒ fine-tune | `openai/whisper-base` | `vinai/PhoWhisper-base` cho tiáº¿ng Viá»‡t |
| `--num-epochs` | Sá»‘ láº§n train qua toÃ n bá»™ dataset | 3 | 3-5 |
| `--batch-size` | Sá»‘ samples má»—i batch | 16 | 8-32 (tÃ¹y GPU) |
| `--learning-rate` | Learning rate | 1e-5 | 1e-5 Ä‘áº¿n 5e-6 |
| `--fp16` | Mixed precision (nhanh hÆ¡n, Ã­t VRAM hÆ¡n) | False | Báº­t náº¿u cÃ³ GPU |
| `--gradient-accumulation-steps` | TÃ­ch lÅ©y gradient | 1 | 2-4 náº¿u batch size nhá» |

### Vá»›i GPU

Náº¿u cÃ³ GPU, thÃªm `--fp16` Ä‘á»ƒ tÄƒng tá»‘c:

```bash
python fine_tune_whisper.py \
    --model-name "vinai/PhoWhisper-base" \
    --train-jsonl "train.jsonl" \
    --audio-dir "archive/vivos/train/waves" \
    --output-dir "./whisper-finetuned" \
    --num-epochs 3 \
    --batch-size 16 \
    --fp16
```

### Vá»›i CPU (cháº­m hÆ¡n nhiá»u)

Giáº£m batch size vÃ  sá»‘ epochs:

```bash
python fine_tune_whisper.py \
    --model-name "vinai/PhoWhisper-base" \
    --train-jsonl "train.jsonl" \
    --audio-dir "archive/vivos/train/waves" \
    --output-dir "./whisper-finetuned" \
    --num-epochs 2 \
    --batch-size 4
```

### Thá»i Gian Training (Æ¯á»›c TÃ­nh)

| Dataset Size | GPU | CPU |
|--------------|-----|-----|
| 100 samples | ~5 phÃºt | ~30 phÃºt |
| 1,000 samples | ~30 phÃºt | ~3 giá» |
| 10,000 samples | ~3 giá» | ~30 giá» |

*Vá»›i model `PhoWhisper-base`, batch size 16, 3 epochs*

---

## ğŸ¯ Sá»­ Dá»¥ng Model ÄÃ£ Fine-tune

### Trong Python

```python
from transformers import pipeline
import torch

# Load model Ä‘Ã£ fine-tune
pipe = pipeline(
    "automatic-speech-recognition",
    model="./whisper-finetuned",  # ÄÆ°á»ng dáº«n Ä‘áº¿n model Ä‘Ã£ fine-tune
    device=0 if torch.cuda.is_available() else -1,
)

# Transcribe audio
result = pipe("path/to/audio.wav")
print(result["text"])
```

### Trong app.py

Sá»­a hÃ m `transcribe_audio()` Ä‘á»ƒ Æ°u tiÃªn model Ä‘Ã£ fine-tune:

```python
# Thay Ä‘á»•i model path
_phowhisper_pipe = pipeline(
    "automatic-speech-recognition",
    model="./whisper-finetuned",  # Model Ä‘Ã£ fine-tune
    device=0 if torch.cuda.is_available() else -1,
)
```

---

## ğŸ”§ Troubleshooting

### Lá»—i: Out of Memory (OOM)

**Giáº£i phÃ¡p:**
1. Giáº£m `--batch-size` (vÃ­ dá»¥: 16 â†’ 8 â†’ 4)
2. TÄƒng `--gradient-accumulation-steps` (vÃ­ dá»¥: 1 â†’ 2 â†’ 4)
3. Sá»­ dá»¥ng model nhá» hÆ¡n (`base` thay vÃ¬ `large`)
4. Báº­t `--fp16` náº¿u cÃ³ GPU

### Lá»—i: CUDA out of memory

**Giáº£i phÃ¡p:**
```bash
# Giáº£m batch size
--batch-size 4

# Hoáº·c sá»­ dá»¥ng CPU
# (bá» --fp16 vÃ  giáº£m batch size)
```

### Training quÃ¡ cháº­m

**Giáº£i phÃ¡p:**
1. Sá»­ dá»¥ng GPU náº¿u cÃ³
2. Báº­t `--fp16`
3. TÄƒng `--batch-size` (náº¿u Ä‘á»§ VRAM)
4. Giáº£m sá»‘ epochs hoáº·c dataset size

### Model khÃ´ng cáº£i thiá»‡n

**Giáº£i phÃ¡p:**
1. Kiá»ƒm tra cháº¥t lÆ°á»£ng dá»¯ liá»‡u training
2. TÄƒng sá»‘ epochs
3. Äiá»u chá»‰nh learning rate (thá»­ 5e-6 hoáº·c 1e-6)
4. ThÃªm nhiá»u dá»¯ liá»‡u training
5. Sá»­ dá»¥ng model lá»›n hÆ¡n (`large` thay vÃ¬ `base`)

### Lá»—i: File audio khÃ´ng tÃ¬m tháº¥y

**Giáº£i phÃ¡p:**
1. Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong JSONL
2. Äáº£m báº£o `--audio-dir` Ä‘Ãºng
3. Cháº¡y `validate_dataset.py` Ä‘á»ƒ kiá»ƒm tra

### Lá»—i: Module not found

**Giáº£i phÃ¡p:**
```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Best Practices

1. **Chia dá»¯ liá»‡u**: 80% train, 20% validation
2. **Augmentation**: CÃ³ thá»ƒ thÃªm noise, speed variation (tÃ¹y chá»n)
3. **Early stopping**: Dá»«ng khi validation loss khÃ´ng giáº£m
4. **Checkpoint**: LÆ°u checkpoint thÆ°á»ng xuyÃªn
5. **Evaluation**: ÄÃ¡nh giÃ¡ trÃªn test set riÃªng

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- [Whisper Paper](https://arxiv.org/abs/2212.04356)
- [PhoWhisper trÃªn Hugging Face](https://huggingface.co/vinai/PhoWhisper-base)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [Fine-tuning Guide](https://huggingface.co/docs/transformers/training)

---

## ğŸ’¡ Tips

- Báº¯t Ä‘áº§u vá»›i model `PhoWhisper-base` - Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u cho tiáº¿ng Viá»‡t
- Fine-tune vá»›i Ã­t dá»¯ liá»‡u trÆ°á»›c (100-500 samples) Ä‘á»ƒ test
- Sá»­ dá»¥ng GPU náº¿u cÃ³ thá»ƒ - nhanh hÆ¡n 10-20 láº§n
- Validate dá»¯ liá»‡u ká»¹ trÆ°á»›c khi train
- LÆ°u checkpoint Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p tá»¥c training náº¿u bá»‹ giÃ¡n Ä‘oáº¡n

---

**ChÃºc báº¡n fine-tuning thÃ nh cÃ´ng! ğŸ‰**


