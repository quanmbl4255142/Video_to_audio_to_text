#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Script phÃ¢n tÃ­ch dataset Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng"""

import json
import os
from collections import Counter

def analyze_dataset():
    """PhÃ¢n tÃ­ch dataset train vÃ  dev"""
    
    # Load data
    train_data = []
    with open('data/train.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            train_data.append(json.loads(line))
    
    dev_data = []
    with open('data/dev.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            dev_data.append(json.loads(line))
    
    def analyze_split(data, name):
        """PhÃ¢n tÃ­ch má»™t split cá»§a dataset"""
        print(f"\n{'='*70}")
        print(f"ğŸ“Š PHÃ‚N TÃCH {name.upper()} DATASET")
        print(f"{'='*70}")
        
        total = len(data)
        positive = sum(1 for d in data if d.get('is_match', True))
        negative = total - positive
        
        sentences = [d['sentence'] for d in data]
        word_lengths = [len(s.split()) for s in sentences]
        char_lengths = [len(s) for s in sentences]
        
        # PhÃ¢n tÃ­ch Ä‘á»™ dÃ i
        avg_words = sum(word_lengths) / len(word_lengths) if word_lengths else 0
        avg_chars = sum(char_lengths) / len(char_lengths) if char_lengths else 0
        min_words, max_words = min(word_lengths), max(word_lengths)
        min_chars, max_chars = min(char_lengths), max(char_lengths)
        
        # PhÃ¢n bá»‘ Ä‘á»™ dÃ i
        word_length_dist = Counter(word_lengths)
        common_lengths = word_length_dist.most_common(10)
        
        print(f"ğŸ“ˆ Tá»•ng sá»‘ máº«u: {total:,}")
        print(f"âœ… Positive (is_match=True): {positive:,} ({positive/total*100:.1f}%)")
        print(f"âŒ Negative (is_match=False): {negative:,} ({negative/total*100:.1f}%)")
        print(f"\nğŸ“ Äá»™ dÃ i cÃ¢u:")
        print(f"   - Trung bÃ¬nh: {avg_words:.1f} tá»«, {avg_chars:.1f} kÃ½ tá»±")
        print(f"   - Min/Max: {min_words}/{max_words} tá»«, {min_chars}/{max_chars} kÃ½ tá»±")
        print(f"\nğŸ“Š PhÃ¢n bá»‘ Ä‘á»™ dÃ i (top 10):")
        for length, count in common_lengths:
            print(f"   - {length} tá»«: {count:,} máº«u ({count/total*100:.1f}%)")
        
        # Kiá»ƒm tra negative samples
        if negative > 0:
            print(f"\nâš ï¸  Negative samples:")
            neg_samples = [d for d in data if not d.get('is_match', True)]
            neg_sentences = [d['sentence'] for d in neg_samples[:5]]
            for i, sent in enumerate(neg_sentences, 1):
                print(f"   {i}. {sent[:80]}...")
        
        # Kiá»ƒm tra cÃ¡c váº¥n Ä‘á» tiá»m áº©n
        issues = []
        
        # 1. CÃ¢u quÃ¡ ngáº¯n
        very_short = sum(1 for wl in word_lengths if wl < 3)
        if very_short > 0:
            issues.append(f"âš ï¸  {very_short} cÃ¢u quÃ¡ ngáº¯n (<3 tá»«) - cÃ³ thá»ƒ gÃ¢y khÃ³ khÄƒn cho model")
        
        # 2. CÃ¢u quÃ¡ dÃ i
        very_long = sum(1 for wl in word_lengths if wl > 50)
        if very_long > 0:
            issues.append(f"âš ï¸  {very_long} cÃ¢u quÃ¡ dÃ i (>50 tá»«) - cÃ³ thá»ƒ bá»‹ cáº¯t bá»›t")
        
        # 3. CÃ¢u trá»‘ng hoáº·c chá»‰ cÃ³ khoáº£ng tráº¯ng
        empty = sum(1 for s in sentences if not s.strip())
        if empty > 0:
            issues.append(f"âŒ {empty} cÃ¢u trá»‘ng - cáº§n loáº¡i bá»")
        
        # 4. Kiá»ƒm tra kÃ½ tá»± Ä‘áº·c biá»‡t
        special_chars = sum(1 for s in sentences if any(c in s for c in ['\\r\\n', '\\n', '\t']))
        if special_chars > 0:
            issues.append(f"âš ï¸  {special_chars} cÃ¢u cÃ³ kÃ½ tá»± Ä‘áº·c biá»‡t (\\r\\n, \\t) - nÃªn normalize")
        
        if issues:
            print(f"\nğŸ” Váº¥n Ä‘á» tiá»m áº©n:")
            for issue in issues:
                print(f"   {issue}")
        else:
            print(f"\nâœ… KhÃ´ng phÃ¡t hiá»‡n váº¥n Ä‘á» nghiÃªm trá»ng")
        
        return {
            'total': total,
            'positive': positive,
            'negative': negative,
            'avg_words': avg_words,
            'avg_chars': avg_chars,
            'min_words': min_words,
            'max_words': max_words
        }
    
    train_stats = analyze_split(train_data, "TRAIN")
    dev_stats = analyze_split(dev_data, "DEV")
    
    # So sÃ¡nh train vs dev
    print(f"\n{'='*70}")
    print(f"ğŸ“Š SO SÃNH TRAIN vs DEV")
    print(f"{'='*70}")
    print(f"Tá»· lá»‡ train/dev: {train_stats['total']/dev_stats['total']:.2f}:1")
    print(f"Äá»™ dÃ i trung bÃ¬nh train: {train_stats['avg_words']:.1f} tá»«")
    print(f"Äá»™ dÃ i trung bÃ¬nh dev: {dev_stats['avg_words']:.1f} tá»«")
    
    if abs(train_stats['avg_words'] - dev_stats['avg_words']) > 2:
        print(f"âš ï¸  Cáº£nh bÃ¡o: Äá»™ dÃ i cÃ¢u train vÃ  dev khÃ¡c nhau Ä‘Ã¡ng ká»ƒ - cÃ³ thá»ƒ gÃ¢y distribution shift")
    
    # Kiá»ƒm tra audio files
    print(f"\n{'='*70}")
    print(f"ğŸµ KIá»‚M TRA AUDIO FILES")
    print(f"{'='*70}")
    
    audio_dir = 'archive/mp3'
    if not os.path.exists(audio_dir):
        audio_dir = 'archive/waves'
    
    if os.path.exists(audio_dir):
        all_audio_files = set(os.listdir(audio_dir))
        train_audio = set(d['audio'] for d in train_data)
        dev_audio = set(d['audio'] for d in dev_data)
        
        train_missing = train_audio - all_audio_files
        dev_missing = dev_audio - all_audio_files
        
        print(f"ğŸ“ ThÆ° má»¥c audio: {audio_dir}")
        print(f"ğŸ“¦ Tá»•ng sá»‘ file audio: {len(all_audio_files):,}")
        print(f"ğŸ¯ Train audio files: {len(train_audio):,}")
        print(f"ğŸ¯ Dev audio files: {len(dev_audio):,}")
        
        if train_missing:
            print(f"âŒ Train: {len(train_missing)} file audio khÃ´ng tá»“n táº¡i")
            print(f"   VÃ­ dá»¥: {list(train_missing)[:3]}")
        
        if dev_missing:
            print(f"âŒ Dev: {len(dev_missing)} file audio khÃ´ng tá»“n táº¡i")
            print(f"   VÃ­ dá»¥: {list(dev_missing)[:3]}")
        
        if not train_missing and not dev_missing:
            print(f"âœ… Táº¥t cáº£ file audio Ä‘á»u tá»“n táº¡i")
    else:
        print(f"âš ï¸  KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c audio: {audio_dir}")

if __name__ == "__main__":
    import sys
    import io
    # Set UTF-8 encoding for Windows console
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    analyze_dataset()

